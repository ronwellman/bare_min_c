\documentclass[../main.tex]{subfiles}

\graphicspath{{pictures/}{../pictures/}}

\chapterimage{chapter_head_7.pdf} % Chapter heading image

\begin{document}
	%----------------------------------------------------------------------------------------
	%	Multithreading
	%----------------------------------------------------------------------------------------
	\chapter{Concurrency}\index{concurency}\label{ch:7}
	Up until this point the programs that we've seen have only been able to execute a single task at any given time.  However, there are times when you may want your program to handle multiple things at the same time.  This is often the case with networked applications.  You may need to listen for incoming connections while processing existing connections.  There are a number of ways to do this and in this chapter we'll talk about a two.  
	One way in which you can do this is to \textbf{fork} a process.  When a process is \textit{forked}, a child process with duplicate memory of the parent process is spun up.  These two processes can work independently of one another.  Another way in which a program may execute multiple tasks at a time is to create another \textbf{thread}.  Threads are independent streams of instructions.  In other words, a single process can have multiple threads where each thread is executing different instructions at the same time.
	
	\section{Forking}\index{fork}\label{sec:fork}
	In our first example of handling multiple tasks at once we'll use the UNIX system call \textit{fork}.  Its fairly simple and straightforward to use and as a result has been incorporated into many different projects.  For example, in certain versions of the Apache Web Server, they use a pre-fork model where they essentially have multiple \textit{forked} processes waiting for a request to come in.  As mentioned earlier, each process (parent and child) has a copy of the memory as it was when the \textit{fork} occurred.  This means there is an initial cost involved when the \textit{fork} occurs to copy memory from the parent process into the child process.  So by \textit{forking} before a request comes in, they incur this cost early on.  Additionally, once a request does come in and its handed to a child process, if something goes wrong with that request, it only affects that process instead of affecting the entire server.  Of course this also comes at the cost of higher resource utilization since each process has a separate copy of the server's memory at the time they were \textit{forked}.
	
	Lets take a look at a simple example of using \textit{fork}:\\
	
	\lstinputlisting[caption={\lstname}]{src/07-concurrency1.c}
	
	On lines 14 - 16 we can see that we are creating variables to store the various process IDs (PID) that we'll see.  We then fill two of those PIDs on lines 18 and 19.
	
	On line 23, we perform a \textit{fork}.  According to the man page:
	
	\begin{quotation}
		On success, the PID of the child process is returned in the parent, and 0 is returned in the child.  On failure, -1 is returned in the parent, no child process is created, and errno is set appropriately.
	\end{quotation}

	This is why we follow up the \textit{fork} with an if statement to detect which process we are working with.  As you can see on lines 31 - 34, the child is merely looking up who its parent is and then calling the echo function that starts on line 43.  On line 39 the parent process calls the same echo function so that we can see them executing simultaneously.  
	
	Since the execution of the echo function happens so quickly, I've added a \textit{nanosleep}\index{nanosleep} to slow it down.  With out this slow down, the parent process often finishes all of its prints before memory has been replicated into the child process and it begins printing as well.
	
	\begin{verbatim}
	$ ./07-concurrency1 
	Program begins with:
		PID: 29803
		ParentPid: 3866
	My Child's PID: 29804
	PARENT: I am a shared string!
	Child Process:
		PID: 0
		ParentPid: 29803
	CHILD: I am a shared string!
	PARENT: I am a shared string!
	CHILD: I am a shared string!
	PARENT: I am a shared string!
	CHILD: I am a shared string!
	PARENT: I am a shared string!
	CHILD: I am a shared string!
	PARENT: I am a shared string!
	CHILD: I am a shared string!
	\end{verbatim}
	
	Notice, that our program starts with a PID of 29803 and once \textit{fork} has taken place, the parent reports that its child has PID 29804.  Also notice that the child indicates it's parent is PID 29803.  Lastly notice that both processes go about their business printing to the screen.  Although this looks like a back and forth movement, this is really artificially created based on the sleeps that were added and the low CPU utilization on my computer when I ran it.
	
	\section{Multithreading}\index{multithreading}
	
	As mentioned, using multiple \textbf{thread}\index{threads} is one way in which a program can execute different tasks concurrently.  \textit{Threads} are lighter weight than using \textit{fork} because each thread does not get its own memory.  This makes communicating between threads easier but can also lead to \textit{race} conditions where values are updated at the same time by two different \text{threads}.  Extra care must be taken to protect shared memory and resources since its easy to mess up. To the beginner, writing \textit{multithreaded} code doesn't sound overly difficult.  However, doing it correctly can be difficult to get working correctly.  Without extensive testing, its easy to write code that will \textit{deadlock}\index{deadlock} under certain conditions.  Whatever this condition is, it leads to a state where at least one thread gets stuck waiting for a resource that will never be available and as a result, it cannot perform any work.
	
	There are two different libraries you'll often see used for multi-threading in C; \texttt{pthread.h} and \texttt{threads.h}.  \texttt{threads.h} was made a part of the C standard library in C11 and for portability reasons, should be what you use going forward.  However, \texttt{pthread.h} has been around for a long time for POSIX systems.  Due to this, you'll still see it taught and used.  In fact, even for current POSIX systems, \texttt{threads.h} is in many ways just a wrapper around \texttt{pthreads.h} and will require you to link in \texttt{pthread.h} during compilation.  Although \texttt{threads.h} was released as a part of the C11 standard, my Ubuntu 20.04 machine did not come with manpages for it.  It does however, have extensive documentation for the various functions in use within \texttt{pthread.h}.  If portability is a concern for you, I suggest you use \texttt{threads.h}.  If you know you'll be writing programs only for POSIX systems, feel free to use \texttt{pthreads.h} as well.  I will attempt to expose you to both.\\
	
	\lstinputlisting[caption={\lstname}, label={lst:threads}]{src/07-concurrency2.c}\index{threads}\index{mutex}
	
	\subsection{Threads.h}
	
	While this example isn't too involved, there are enough elements that you can see multi-threading in action.  The first thing to notice is that on line 3 we are using \textit{threads.h}.  This means we are using the C standard threading library. Lets follow the life of the actual threads.  On line 20, we see a \textit{thrd\_t struct} pointer declared.  On line 43, space for 5 threads is allocated and then on line 46 they are put to work.  During the \textit{thrd\_create} the individual threads are given a function to perform.  In this case, each thread will run the \textit{doWork} function.  The last argument in the \textit{thrd\_create} function is the argument that will be passed to the \textit{doWork} function.  In this case, we are not sending anything so it is set to NULL.  The function \textit{doWork} has a prescribed function prototype.  It must be of the form: \textit{int(*)(void\*)}.  This is means the function takes in a \textit{void *} as an argument and returns an integer.  This is different than the function prototype you'll pass to \textit{pthread\_create}.  It takes the form: \textit{void *(*)(void *)}.  This means that it takes in a \textit{void *} and returns a \textit{void *}. 
	
	So execution for each threads now starts at the \textit{doWork} function on line 66.  On line 73 we look up the thread ID.  This is only needed as it was nice to use during printing to see which thread it was that was perfoming work.  On line 86 we see the \textit{thrd\_yield} function used.  This does little in the context of this program but is a way for the thread to indicate to the OS that its ok to schedule it at a lower priority.  This could be due to the thread waiting for an action that may take awhile.  On line 90 we see \textit{thrd\_exit} being called.  This is how the thread returns values from the function.  So now that the thread is done with all of its work, its up to the main thread to call \textit{thrd\_join} on line 55.  This is a blocking action and the main thread will wait here for the thread it is joining to complete.  One by one the threads finish their work, exit, and are joined by the main thread.
	
	\subsection{Mutex}
	
	Another aspect of this program is the use of a \textbf{mutex}\index{mutex} (Mutual Exclusion).  In multithreaded applications, its important to protect shared memory that multiple threads could potentially access or change at the same time.  In the context of this example, there is a \textit{queue} that has work being enqueued by the main thread and dequeued by the worker threads.  Since it could cause issues if multiple threads tried to dequeue a job at the same time, we use a \textit{mutex} to protect it.  In order for a thread to access the \textit{queue} they have to first lock the \textit{mutex}.  Only one thread can lock it at a time so if the \textit{mutex} is already locked, other threads will wait.  Once it is unlocked, another thread will attempt to lock it.
	
	Since each thread must have access to the \textit{mutex} it is created globally on line 11.  On line 24 we zero out the \textit{mutex} and then initialize it on line 25.  We declare the \textit{mutex} to be a plain type (non-recursive - can only be locked once).  For the purpose of this program, the main thread doesn't need to lock the \textit{mutex} when enqueueing work since the other threads don't exist yet.  However, its left as a reminder that any thread, to include the main thread, needs to use a \textit{mutex} when accessing a shared resource.  On lines 75 and 78 we see the threads also utilize the \textit{mutex} before accessing the \textit{queue}.  Lastly, on line 61 we destroy the \textit{mutex} releasing any memory it is holding from when it was initialized.
	
	Let's see what running this example looks like.
	
	\begin{verbatim}
	Enqueu work.
	Creating Threads.
	Creating Threads.
	Creating Threads.
	140045949937408: dequeue: A
	Creating Threads.
	140045941544704: dequeue: B
	Creating Threads.
	140045864400640: dequeue: C
	140045864400640: dequeue: E
	140045949937408: dequeue: F
	140045856007936: dequeue: D
	140045949937408: dequeue: I
	140045941544704: dequeue: H
	140045941544704: No work.
	140045847615232: dequeue: J
	140045847615232: No work.
	140045856007936: No work.
	140045949937408: No work.
	140045864400640: dequeue: G
	140045864400640: No work.
	Thread 0 joined with result: 0
	Thread 1 joined with result: 0
	Thread 2 joined with result: 0
	Thread 3 joined with result: 0
	Thread 4 joined with result: 0
	\end{verbatim}
	
	As we can see, although the \textit{queue} releases the jobs in the same order they were enqueued, the individual threads printed them in a different order.  This is because each individual thread is operating independently of the others and may get scheduled differently by the OS.  These little scheduling differences result in a few of the jobs being printed out in a different order.
	
	\subsection{Condition Variables}
	
	In the previous example, the threads continued to check if there was work to be done and as soon as there wasn't, they closed down.  It demonstrated the use of \textit{threads} and using a \textit{mutex} to protect a shared resource (the queue).  However, this may not be very practical.  In the next example, we'll not only switch to using the \textit{pthread} library but we'll also use \textbf{condition variables}\index{condition variables} to signal the threads when they need to "wake" up and perform some work.  There are number of functions that we could use to interact with our \textit{condition variable}.  The following are taken directly from the man pages:
	

	\textbf{pthread\_cond\_init} - initializes the condition variable cond.
		
	\textbf{pthread\_cond\_destroy} - destroys a condition variable, freeing the resources it might hold.
		
	\textbf{pthread\_cond\_wait} - atomically unlocks the mutex (as per pthread\_unlock\_mutex) and waits for the condition variable cond to be signaled. The thread execution is suspended and does not consume any  CPU	time  until the condition variable is signaled. The mutex must be locked by the calling thread on entrance to pthread\_cond\_wait. Before returning to the calling thread, pthread\_cond\_wait re-acquires mutex (as per pthread\_lock\_mutex).
		
	\textbf{pthread\_cond\_signal} - restarts  one of the threads that are waiting on the condition variable cond. If no threads are waiting on cond, nothing happens. If several threads are waiting on cond, exactly one is restarted, but it is not specified which.
		
	\textbf{pthread\_cond\_broadcast} - restarts all the threads that are waiting on the condition variable cond. Nothing happens if no threads are waiting on cond.

	As we can see, threads will utilize a \textit{mutex} along with \textit{pthread\_cond\_wait}.  Once waiting, they will essentially stop consuming CPU cycles.  Another thread, most likely the main thread, will then either awaken a single thread with \textit{pthread\_cond\_signal} or all waiting threads with \textit{pthread\_cond\_broadcast}.
	
	\subsubsection{Thread Pool}\index{thread pool}
	The last example and the following example contain parts that make up a very simple bare bones version of a \textbf{thread pool} where there are threads laying in wait for work to be performed.  Lets take a look at how this pans out in our next example. \\
	
	\lstinputlisting[caption={\lstname}, label={lst:threads}]{src/07-concurrency3.c}\index{threads}\index{condition variables}\index{thread pool}
	
	On lines 18-20, we can see there are two \textit{mutexes} (\textit{phtread\_mute\_t}) being declared globally so that each thread has access to them.  Additionally, we have a \textit{condition variable} (\textit{pthread\_cond\_t}) being created as well.  One \textit{mutex} will be used in conjunction with this \textit{condition variable}. All three are initialized on lines 37-41 and destroyed on line 90-92.
	
	On line 46 we can see each of our different threads being created and added to an array.  The threads are told to perform the function \texttt{doWork} which takes no input and returns nothing either.
	
	Inside of the \texttt{doWork} function we can see that the thread looks up its ID utilizing \textit{pthread\_self} on line 99.  We can also see on line 103 where the thread looks to see if it should keep looping.
	
	Lines 106 and 116 are the bread and butter of what will keep the threads from wasting CPU cycles when there is no work to be performed.  In this case, they lock the \texttt{mtxJobs} \textit{mutex} and then begin waiting on the \textit{condition variable} by using \textit{pthread\_cond\_wait}.  This unlocks the \texttt{mtxJobs} \textit{mutex} and puts the thread in a wait state.
	
	Once the main thread determines there is work to be performed, on line 75 it utilizes \textit{pthread\_cond\_signal} to signal one of the waiting threads to wake up.  When this is done, the thread has to re-unlock the \texttt{mtxJobs} \textit{mutex}. It then proceeds to perform work until there is nothing for it to do.  At this point, it checks to see if it should continue looping and if so, it goes into a wait state once again.
	
	Once the main thread no longer has any work to assign, on line 80 it sets the \texttt{processJobs} flag to \texttt{false} and on line 82 sends a broadcast to all the threads with \textit{pthread\_cond\_signal}.  At this point, each thread wakes up and checks to see if there is any work remaining, sees that \texttt{processJobs} flag is no longer set, and returns by running \textit{pthread\_exit} on line 153.
	
	Now that the work has been created, assigned, and hopefully performed, the main thread performs a \textit{pthread\_join} on line 85 for each of the threads.
	
	Lets see what the results look like.
	
	\begin{verbatim}
	$ ./07-concurrency3 
	Enqueing and signaling.
	Enqueing and signaling.
	Enqueing and signaling.
	Enqueing and signaling.
	139982923020032 - 9/20 items were even.
	139982923020032 - 7/20 items were even.
	Enqueing and signaling.
	139982923020032 - 7/20 items were even.
	139982931412736 - 9/20 items were even.
	139982914627328 - 13/20 items were even.
	Enqueing and signaling.
	Enqueing and signaling.
	139982897841920 - 11/20 items were even.
	139982881056512 - 12/20 items were even.
	139982881056512 - 9/20 items were even.
	Enqueing and signaling.
	Enqueing and signaling.
	139982872663808 - 8/20 items were even.
	139982914627328 - 10/20 items were even.
	Enqueing and signaling.
	Send broadcast.
	Joining 0.
	Joining 1.
	Joining 2.
	Joining 3.
	Joining 4.
	Joining 5.
	Joining 6.
	Joining 7.
	\end{verbatim}
	
	A quick glance at the above output and we can see that ten jobs were created and the work was performed by 6 different threads.  Your output will undoubtedly be different than mine.
	
\end{document}